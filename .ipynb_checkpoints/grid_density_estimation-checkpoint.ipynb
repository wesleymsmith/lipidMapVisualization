{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization Cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Colab specific initialization cell\n",
    "#For those users running this on google colab, this cell can be\n",
    "#turned into a code cell and run. It will have colab install needed packages and,\n",
    "#most importantly, it will clone the 'dataFiles' folder of this repository\n",
    "#so that you can access it here.\n",
    "#Use ctrl+m+y to convert to code cell in google colab\n",
    "\n",
    "!apt-get install subversion\n",
    "!svn checkout https://github.com/wesleymsmith/lipidMapVisualization/trunk/dataFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import collections\n",
    "import sys\n",
    "import gc\n",
    "import os\n",
    "import sklearn as skl\n",
    "from sklearn import decomposition\n",
    "from sklearn import metrics\n",
    "from sklearn import discriminant_analysis\n",
    "from sklearn import cluster\n",
    "import tqdm\n",
    "import ipywidgets\n",
    "import copy\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, interactive_output\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "\n",
    "As always, our data is saved in chunks due to size limits.\n",
    "Here, we need to load both the clustering data as well as the center of mass data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveArrayChunks(pathBase,arr,nChunks,axis=0,\n",
    "                    pbar=None):\n",
    "    \"\"\"\n",
    "        pathBase: the prefix of the file path to save each chunk to.\n",
    "                    files will be named pathBase.chunk_#.npy, where # is\n",
    "                    a zero padded integer (to make loading, sorting, etc easier)\n",
    "        arr: the array to be saved\n",
    "        axis: the axis along which to split the array ()\n",
    "    \"\"\"\n",
    "    arrayChunks=np.array_split(arr,nChunks,axis=axis)\n",
    "    ndigits=int(np.ceil(np.log10(nChunks)))\n",
    "    digitStr='%'+'0%g'%ndigits+'g'\n",
    "    if not pbar is None:\n",
    "        pbar.n=len(arrayChunks)\n",
    "        pbar.refresh()\n",
    "    for iChunk,arrayChunk in enumerate(arrayChunks):\n",
    "        outPath='.'.join([pathBase,'chunk_%s'%(digitStr%iChunk),'npy'])\n",
    "        np.save(outPath,arrayChunk)\n",
    "        if not pbar is None:\n",
    "            pbar.update()\n",
    "            \n",
    "def loadArrayChunks(pathBase,nChunks,axis=0,\n",
    "                    pbar=None):\n",
    "    arrayChunks=[]\n",
    "    ndigits=int(np.ceil(np.log10(nChunks)))\n",
    "    digitStr='%'+'0%g'%ndigits+'g'\n",
    "    if not pbar is None:\n",
    "        pbar.n=len(arrayChunks)\n",
    "        pbar.refresh()\n",
    "    for iChunk in np.arange(nChunks):\n",
    "        dataPath='.'.join([pathBase,'chunk_%s'%(digitStr%iChunk),'npy'])\n",
    "        arrayChunks.append(np.load(dataPath))\n",
    "        if not pbar is None:\n",
    "            pbar.update()\n",
    "    return np.concatenate(arrayChunks,axis=axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data sets "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9ba11198c7c41e6b4eb31d4485c3e1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style=u'info', max=1), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " POPC POPS PIP2 \n",
      "\n",
      "done loading data\n",
      "--- --- --- ---\n",
      "POPC (1176, 2001, 3)\n",
      "POPS (1282, 1592, 3)\n",
      "PIP2 (1290, 1592, 3)\n"
     ]
    }
   ],
   "source": [
    "dataFileDir='dataFiles'\n",
    "comDataDir='/'.join([dataFileDir,'headgroupCoords'])\n",
    "leafletClusteringDir='/'.join([dataFileDir,'leafletClustering'])\n",
    "\n",
    "comFileTypeName='headgroup_COM_coords'\n",
    "\n",
    "systems=['POPC','POPS','PIP2']\n",
    "\n",
    "nChunks=4\n",
    "\n",
    "comDataDict={}\n",
    "print 'Loading data sets ',\n",
    "with tqdm.tqdm_notebook() as pbar:\n",
    "    for system in systems:\n",
    "        print system,\n",
    "        pbar.set_description_str(system)\n",
    "        comFileNameBase='.'.join([system,comFileTypeName])\n",
    "        comFilePathBase='/'.join([comDataDir,comFileNameBase])\n",
    "        comDataDict[system]=loadArrayChunks(comFilePathBase,nChunks=nChunks,axis=1,\n",
    "                                            pbar=pbar)\n",
    "        gc.collect()\n",
    "    print ''\n",
    "print 'done loading data'\n",
    "print '--- --- --- ---'\n",
    "\n",
    "for setKey in comDataDict:\n",
    "    print setKey,\n",
    "    print comDataDict[setKey].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loading clustering data sets "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "badecdb9b2bd47208e5b98869d3d3476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style=u'info', max=1), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " POPC PIP2 POPS \n",
      "\n",
      "done loading data\n",
      "--- --- --- ---\n",
      "POPC (2001, 1176)\n",
      "POPS (1592, 1282)\n",
      "PIP2 (1592, 1290)\n"
     ]
    }
   ],
   "source": [
    "clusterDataDir='dataFiles/leafletClustering/'\n",
    "clusterFileTypeName='leaflet_clustering_array'\n",
    "\n",
    "systems=['POPC','PIP2','POPS']\n",
    "\n",
    "nChunks=3\n",
    "\n",
    "clusterDataDict={}\n",
    "print 'Loading clustering data sets ',\n",
    "with tqdm.tqdm_notebook() as pbar:\n",
    "    for system in systems:\n",
    "        print system,\n",
    "        pbar.set_description_str(system)\n",
    "        clusterFileNameBase='.'.join([system,clusterFileTypeName])\n",
    "        clusterFilePathBase='/'.join([clusterDataDir,clusterFileNameBase])\n",
    "        clusterDataDict[system]=loadArrayChunks(clusterFilePathBase,nChunks=nChunks,axis=0,\n",
    "                                            pbar=pbar)\n",
    "        gc.collect()\n",
    "    print ''\n",
    "print 'done loading data'\n",
    "print '--- --- --- ---'\n",
    "\n",
    "for setKey in clusterDataDict:\n",
    "    print setKey,\n",
    "    print clusterDataDict[setKey].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Membrane Density Calculation\n",
    "\n",
    "Here we seek to calculate lipid density based upon the center of mass coordinates of our lipid.\n",
    "\n",
    "Before we can do so, we must first define our XY coordinate grids\n",
    "\n",
    "## XY grid calculation\n",
    "\n",
    "These simulations have been centered such that the center of mass of the protein lies on the origin. While the size of the simulation grid does fluctuate slightly from one frame to another due to use of a simulation barostat (NPT ensemble) the change is relatively small. We will thus attempt to use the same XY grid setup for all density and height calculations. This will simplify many computational considerations. It also means that we only need to calculate the XY grid one time. If this is already done, then you don't need to run the next cell, just run the loading cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- POPC ---\n",
      "POPC Grid shape:  (230, 229)\n",
      "POPC Grid Bounds:  [[ -7.08916131  -5.28010502]\n",
      " [220.81656324 222.76967284]]\n",
      "saving to disk...\n",
      "--- POPS ---\n",
      "POPS Grid shape:  (232, 233)\n",
      "POPS Grid Bounds:  [[ -7.18940158  -4.86527905]\n",
      " [224.4948777  225.75348258]]\n",
      "saving to disk...\n",
      "--- PIP2 ---\n",
      "PIP2 Grid shape:  (235, 233)\n",
      "PIP2 Grid Bounds:  [[ -2.96129944  -3.34464858]\n",
      " [229.03306636 229.90644927]]\n",
      "saving to disk...\n"
     ]
    }
   ],
   "source": [
    "#Compute an XY grid for each system and save it to disk.\n",
    "#only needs to be run once unless new systems are being analyzed.\n",
    "outDir=dataFileDir\n",
    "gridSpacing=1.0 #1 Å grid\n",
    "for system in comDataDict:\n",
    "    print '--- %s ---'%system\n",
    "    comData=comDataDict[system]\n",
    "    gridBounds=np.array([\n",
    "            [np.min(comData[:,0]),np.min(comData[:,1])],\n",
    "            [np.max(comData[:,0]),np.max(comData[:,1])]])\n",
    "    centerX=np.mean(gridBounds[:,0])\n",
    "    centerY=np.mean(gridBounds[:,1])\n",
    "    nX=int(np.ceil((gridBounds[1,0]-gridBounds[0,0])/gridSpacing))+1\n",
    "    nY=int(np.ceil((gridBounds[1,1]-gridBounds[0,1])/gridSpacing))+1\n",
    "    pointsX=np.linspace(centerX-(nX-1)*gridSpacing/2,\n",
    "                        centerX+(nX-1)*gridSpacing/2,\n",
    "                        nX)\n",
    "    pointsY=np.linspace(centerY-(nY-1)*gridSpacing/2,\n",
    "                        centerY+(nY-1)*gridSpacing/2,\n",
    "                        nY)\n",
    "    gridX,gridY=np.meshgrid(pointsX,pointsY)\n",
    "    print '%s Grid shape: '%system,\n",
    "    print gridX.shape\n",
    "    print '%s Grid Bounds: '%system,\n",
    "    print gridBounds\n",
    "    print 'saving to disk...'\n",
    "    outFileName='.'.join([system,'gridX.npy'])\n",
    "    outFilePath='/'.join([outDir,outFileName])\n",
    "    np.save(outFilePath,arr=gridX)\n",
    "    outFileName='.'.join([system,'gridY.npy'])\n",
    "    outFilePath='/'.join([outDir,outFileName])\n",
    "    np.save(outFilePath,arr=gridY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the XY grid data from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- POPC ---\n",
      "POPC Grid shape:  (230, 229)\n",
      "POPC Grid Bounds:  [[-7.136299035217178, -5.755216087030789], [220.86370096478282, 223.2447839129692]]\n",
      "--- POPS ---\n",
      "POPS Grid shape:  (232, 233)\n",
      "POPS Grid Bounds:  [[-7.34726194302722, -5.0558982344096535], [224.6527380569728, 225.94410176559035]]\n",
      "--- PIP2 ---\n",
      "PIP2 Grid shape:  (235, 233)\n",
      "PIP2 Grid Bounds:  [[-2.9641165389713535, -3.7190996543211696], [229.03588346102865, 230.28090034567884]]\n"
     ]
    }
   ],
   "source": [
    "gridXdict={}\n",
    "gridYdict={}\n",
    "gridBoundsDict={}\n",
    "for system in comDataDict:\n",
    "    print '--- %s ---'%system\n",
    "    gridXfileName='.'.join([system,'gridX.npy'])\n",
    "    gridXfilePath='/'.join([dataFileDir,gridXfileName])\n",
    "    gridXdict[system]=np.load(gridXfilePath)\n",
    "    gridYfileName='.'.join([system,'gridY.npy'])\n",
    "    gridYfilePath='/'.join([dataFileDir,gridYfileName])\n",
    "    gridYdict[system]=np.load(gridYfilePath)\n",
    "    print '%s Grid shape: '%system,\n",
    "    print gridXdict[system].shape\n",
    "    gridBoundsDict[system]=[\n",
    "        [np.min(gridXdict[system]),np.min(gridYdict[system])],\n",
    "        [np.max(gridXdict[system]),np.max(gridYdict[system])]\n",
    "    ]\n",
    "    print '%s Grid Bounds: '%system,\n",
    "    print gridBoundsDict[system]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Membrane headgroup density\n",
    "\n",
    "Now that we have the XY grid setup for each system, we can begin computing lipid density grids.\n",
    "\n",
    "For now, we will consider only the density for the headgroups. This can be extended later to accomodate additional sets of lipid atoms if needed, however, the method for doing so should be essentially the same.\n",
    "\n",
    "Here we will use a rather tried and tested method for density estimation, a gaussian kernel density estimate. There are, of course other options, we could use the same 1/r grid assignment scheme we are using for heights, or pick any of a number of other kernels. Gaussian kernels seem to be one of the most common and implementations are widely avaialable and well documented and tested.\n",
    "\n",
    "Below we define a method to encapsulate computing the kernel density estimate for each frame then computing its value at each grid point in our XY grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridDensity2D(coordXY,gridX,gridY,**kwargs):\n",
    "    gridInds=np.nonzero(1.0+0.*gridX)\n",
    "    sampleCoords=np.array([\n",
    "        gridX[gridInds],\n",
    "        gridY[gridInds]\n",
    "    ]).T\n",
    "    gdV=np.exp(skl.neighbors.KernelDensity(**kwargs).fit(\n",
    "                    coordXY).score_samples(sampleCoords))\n",
    "    dmat=np.zeros(gridX.shape)\n",
    "    dmat[gridInds]=gdV\n",
    "    return dmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One final detail to be considered. This gaussian kernel requires a 'bandwidth' parameter to function.\n",
    "While the default is to generate one based on an estimate scheme, the result is often very heavily smoothed.\n",
    "We would like a little finer detail here. Since we know that phosphate groups have an ionic radius of about\n",
    "2.4 Å, we can use that as our bandwidth parameter.\n",
    "\n",
    "Please note that we are using a 1 Å grid, so we can directly enter 2.4 as our bandwidth parameter. If you use\n",
    "a different grid spacing, you would need to update this accordingly since this 'bandwidth' is essentially in terms of grid units. E.g. if you use a 2 Å grid, you would need a bandwidth of 1.2.\n",
    "\n",
    "As a finaly note, this method works relatively well for the roughly 1k headgroups we have in total. However, \n",
    "it scales rather poorly as you increase the total number of points being considered. If there are 10k or more points to be estimated, a different approach may be needed... of course, the same is also true of the 1/r based grid height interpolation method as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- POPC ---\n",
      "Computing grid density\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "806aa19b4b794d14a3a04f6d794efa80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2001), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- PIP2 ---\n",
      "Computing grid density\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1991d6b27afc48b5b075e23cbd41d1d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1592), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "upperDensityDict={}\n",
    "lowerDensityDict={}\n",
    "dKwds={'bandwidth':2.4}\n",
    "densitySubDir='leafletDensity'\n",
    "for system in systems:\n",
    "    print '--- %s ---'%system\n",
    "    leafletIDs=clusterDataDict[system]\n",
    "    gridBounds=gridBoundsDict[system]\n",
    "    gridX=gridXdict[system]\n",
    "    gridY=gridYdict[system]\n",
    "    comData=comDataDict[system]\n",
    "    print 'Computing grid density'\n",
    "    with tqdm.tqdm_notebook(\n",
    "        total=comData.shape[1]\n",
    "    ) as pbar:\n",
    "        pbar.set_description(system)\n",
    "        upperDensityDict[system]=np.zeros(\n",
    "            [comData.shape[1],gridX.shape[1],gridX.shape[0]])\n",
    "        lowerDensityDict[system]=np.zeros(\n",
    "            [comData.shape[1],gridX.shape[1],gridY.shape[0]])\n",
    "        for frame in np.arange(comData.shape[1]):\n",
    "            coordData=comData[:,frame,:2]\n",
    "            pbar.set_description_str('%g u'%frame)\n",
    "            upperDensityDict[system][frame,:,:]=np.rot90(\n",
    "                gridDensity2D(coordData[leafletIDs[frame]==0],\n",
    "                              gridX,gridY,**dKwds))\n",
    "            pbar.set_description_str('%g l'%frame)\n",
    "            lowerDensityDict[system][frame,:,:]=np.rot90(\n",
    "                gridDensity2D(coordData[leafletIDs[frame]==1],\n",
    "                              gridX,gridY,**dKwds))\n",
    "            pbar.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of the arrays to be saved is much greater than the allowed 20M limit.\n",
    "Once again, we need to save in chunks. The resulting arrays were on the order of 800M\n",
    "from previous testing, so about 50 chunks should yield sizes well within the 20M limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nchunks=50\n",
    "witupperDensityDictsityDict.tqdm_notebook() as saveBar:\n",
    "    saveBar.refresh()\n",
    "    for system in upperDensityDict:\n",
    "        print '--- %s ---'%system\n",
    "        print 'Saving upper leaflet density (array shape = ',\n",
    "        print upperDensityDict[system].shape,\n",
    "        print ')'\n",
    "        outFileNameBase='.'.join([system,'upperLeaflet.density'])\n",
    "        outFilePathBase='/'.join([dataFileDir,densitySubDir,outFileNameBase])\n",
    "        saveArrayChunks(outFilePathBase,upperDensityDict[system],\n",
    "                        nChunks=nchunks,pbar=saveBar)\n",
    "        print 'Saving lower leaflet density (array shape = ',\n",
    "        print lowerDensityDict[system].shape,\n",
    "        print ')'\n",
    "        outFileNameBase='.'.join([system,'lowerLeaflet.density.npy'])\n",
    "        outFilePathBase='/'.join([dataFileDir,densitySubDir,outFileNameBase])\n",
    "        saveArrayChunks(outFilePathBase,lowerDensityDict[system],\n",
    "                        nChunks=nchunks,pbar=saveBar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38c84e594f5c46d99cdb803da231366c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SEJveChjaGlsZHJlbj0oVkJveChjaGlsZHJlbj0oRHJvcGRvd24oZGVzY3JpcHRpb249dSdTeXN0ZW0gMTogJywgb3B0aW9ucz0oJ1BPUEMnLCAnUE9QUycsICdQSVAyJyksIHZhbHVlPSdQT1DigKY=\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "361f93bcdf7c4467bdc1b72ee517d53c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "systemWidget1=widgets.Dropdown(\n",
    "                 options=comDataDict.keys(),\n",
    "                 description='System 1: ')\n",
    "frameWidget1=widgets.IntRangeSlider(description='FrameRange1:',\n",
    "                              max=comDataDict[systemWidget1.value].shape[1],\n",
    "                              continuous_update=False)\n",
    "\n",
    "systemWidget2=widgets.Dropdown(\n",
    "                 options=comDataDict.keys(),\n",
    "                 description='System 2: ')\n",
    "frameWidget2=widgets.IntRangeSlider(description='FrameRange2:',\n",
    "                              max=comDataDict[systemWidget2.value].shape[1],\n",
    "                              continuous_update=False)\n",
    "\n",
    "def updateFrameRange1(*args):\n",
    "    frameRange1=[0,comDataDict[systemWidget1.value].shape[1]]\n",
    "    frameWidget1.min=frameRange1[0]\n",
    "    frameWidget1.max=frameRange1[1]\n",
    "frameWidget1.observe(updateFrameRange1)\n",
    "\n",
    "def updateFrameRange2(*args):\n",
    "    frameRange2=[0,comDataDict[systemWidget2.value].shape[1]]\n",
    "    frameWidget2.min=frameRange2[0]\n",
    "    frameWidget2.max=frameRange2[1]\n",
    "frameWidget2.observe(updateFrameRange2)\n",
    "\n",
    "def addWindowMeanDensity(\n",
    "    frameRange,gridBounds,\n",
    "    densityData,ax):\n",
    "    plotData=np.mean(\n",
    "        densityData[\n",
    "            frameRange[0]:frameRange[1],:],\n",
    "        axis=0)\n",
    "    dPlot=ax.imshow(\n",
    "        np.rot90(np.rot90(plotData.T)),\n",
    "        extent=(gridBounds[0,0],gridBounds[1,0],\n",
    "                gridBounds[0,1],gridBounds[1,1]))\n",
    "    return(dPlot)\n",
    "\n",
    "def addWindowMeanCoords(\n",
    "    frameRange,coordData,\n",
    "    labelVal,colorVal,ax,\n",
    "    crdSize=4,crdShape='x'):\n",
    "    plotData=np.mean(\n",
    "        coordData[:,frameRange[0]:frameRange[1],:],\n",
    "        axis=1)\n",
    "    cPlot=ax.scatter(\n",
    "        plotData[:,0],plotData[:,1],\n",
    "        c=colorVal,label=labelVal,\n",
    "        s=crdSize,marker=crdShape)\n",
    "    return(cPlot)\n",
    "\n",
    "def showDensities(system1,system2,frameSet1,frameSet2):\n",
    "    print \"systems: %s %s\"%(system1,system2)\n",
    "    print \"system1 frames: %g\"%comDataDict[system1].shape[1]\n",
    "    print \"system2 frames: %g\"%comDataDict[system2].shape[1]\n",
    "    print \"frame range 1:\",\n",
    "    range1=np.clip(frameSet1,0,comDataDict[system1].shape[1])\n",
    "    print range1\n",
    "    print \"frame range 2:\",\n",
    "    range2=np.clip(frameSet2,0,comDataDict[system2].shape[1])\n",
    "    print range2\n",
    "    \n",
    "    plotSystems=[system1,system2]\n",
    "    plotRanges=[frameSet1,frameSet2]\n",
    "        \n",
    "    fig,axs=plt.subplots(3,len(plotSystems))\n",
    "    plotWidth=12\n",
    "    plotHeight=plotWidth/2.*len(plotSystems)+1.\n",
    "    fig.set_figheight(plotWidth)\n",
    "    fig.set_figwidth(plotHeight)\n",
    "    \n",
    "    shrinkVal=.75\n",
    "    crdSize=3\n",
    "    crdShape='x'\n",
    "    \n",
    "    leafletCoordColors=[\"#992299\",\"#cc88cc\"]\n",
    "    \n",
    "    for iSystem,system in enumerate(plotSystems):\n",
    "        frameRange=plotRanges[iSystem]\n",
    "        leafletIDs=np.array(np.round(\n",
    "            np.mean(clusterDataDict[system],axis=0)),dtype=int)\n",
    "        gridBounds=np.array(gridBoundsDict[system])\n",
    "        \n",
    "        #upper leaflet plot\n",
    "        ax=axs[0][iSystem]\n",
    "        densData=upperDensityDict[system]\n",
    "        coordInds=(leafletIDs==0)\n",
    "        coordData=comDataDict[system][coordInds]\n",
    "        coordLabel=\"Upper\"\n",
    "        coordColor=leafletCoordColors[0]\n",
    "        dPlot=addWindowMeanDensity(frameRange,gridBounds,\n",
    "                                   densData,ax)\n",
    "        cPlot=addWindowMeanCoords(frameRange,coordData,\n",
    "                                  coordLabel,coordColor,\n",
    "                                  ax)\n",
    "        ax.legend(title='Leaflet',loc='upper left')\n",
    "        ax.set_title(\"%s Upper Leaflet\"%system)\n",
    "        plt.colorbar(dPlot,ax=ax,shrink=shrinkVal)\n",
    "        \n",
    "        #mean leaflet plot\n",
    "        ax=axs[1][iSystem]\n",
    "        densData=np.mean([\n",
    "                upperDensityDict[system],\n",
    "                lowerDensityDict[system]\n",
    "            ],axis=0)\n",
    "        dPlot=addWindowMeanDensity(frameRange,gridBounds,\n",
    "                                   densData,ax)\n",
    "        coordInds=(leafletIDs==0)\n",
    "        coordData=comDataDict[system][coordInds]\n",
    "        coordLabel=\"Upper\"\n",
    "        coordColor=leafletCoordColors[0]\n",
    "        cPlot=addWindowMeanCoords(frameRange,coordData,\n",
    "                                  coordLabel,coordColor,\n",
    "                                  ax)\n",
    "        coordInds=(leafletIDs==1)\n",
    "        coordData=comDataDict[system][coordInds]\n",
    "        coordLabel=\"Lower\"\n",
    "        coordColor=leafletCoordColors[1]\n",
    "        cPlot=addWindowMeanCoords(frameRange,coordData,\n",
    "                                  coordLabel,coordColor,\n",
    "                                  ax)\n",
    "        ax.legend(title=\"Leaflet\",loc='upper left')\n",
    "        ax.set_title(\"%s Mean\"%system)\n",
    "        plt.colorbar(dPlot,ax=ax,shrink=shrinkVal)\n",
    "        \n",
    "        #lower leaflet plot\n",
    "        ax=axs[2][iSystem]\n",
    "        densData=lowerDensityDict[system]\n",
    "        dPlot=addWindowMeanDensity(frameRange,gridBounds,\n",
    "                                   densData,ax)\n",
    "        coordInds=(leafletIDs==1)\n",
    "        coordLabel=\"Lower\"\n",
    "        coordColor=leafletCoordColors[1]\n",
    "        cPlot=addWindowMeanCoords(frameRange,coordData,\n",
    "                                  coordLabel,coordColor,\n",
    "                                  ax)\n",
    "        ax.legend(title=\"Leaflet\",loc='upper left')\n",
    "        ax.set_title(\"%s Lower Leaflet\"%system)\n",
    "        plt.colorbar(dPlot,ax=ax,shrink=shrinkVal)\n",
    "        plt.title(system)\n",
    "        plt.tight_layout()\n",
    "    \n",
    "controlPannelDict={'system1':systemWidget1, 'system2':systemWidget2,\n",
    "               'frameSet1':frameWidget1,'frameSet2':frameWidget2}\n",
    "dispOut=interactive_output(showDensities,controlPannelDict)\n",
    "controlColumn1=widgets.VBox([systemWidget1,frameWidget1])\n",
    "controlColumn2=widgets.VBox([systemWidget2,frameWidget2])\n",
    "controlPannel=widgets.HBox([controlColumn1,controlColumn2])\n",
    "display(controlPannel,dispOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
