{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytraj as pt\n",
    "import pytraj.utils.progress\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import ggplot\n",
    "import collections\n",
    "import sys\n",
    "import gc\n",
    "import os\n",
    "import sklearn as skl\n",
    "from sklearn import decomposition\n",
    "from sklearn import metrics\n",
    "from sklearn import discriminant_analysis\n",
    "from sklearn import cluster\n",
    "import tqdm\n",
    "import nglview as nv\n",
    "import ipywidgets\n",
    "import copy\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses the lipid center of mass coordinate data generated by the \n",
    "'extract_membrane_headgroups.ipynb' notebook to predict which leaflet each lipid resdiue\n",
    "belonged too. The resulting data will be used to construct height and density maps for\n",
    "individual leaflets.\n",
    "\n",
    "Since the data files are too large to store as single files on github, we will use the\n",
    "functions defined in 'extract_membrane_headgroups.ipynb' to load and save datafiles piecewise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveArrayChunks(pathBase,arr,nChunks,axis=0,\n",
    "                    pbar=None):\n",
    "    \"\"\"\n",
    "        pathBase: the prefix of the file path to save each chunk to.\n",
    "                    files will be named pathBase.chunk_#.npy, where # is\n",
    "                    a zero padded integer (to make loading, sorting, etc easier)\n",
    "        arr: the array to be saved\n",
    "        axis: the axis along which to split the array ()\n",
    "    \"\"\"\n",
    "    arrayChunks=np.array_split(arr,nChunks,axis=axis)\n",
    "    ndigits=int(np.ceil(np.log10(nChunks)))\n",
    "    digitStr='%'+'0%g'%ndigits+'g'\n",
    "    if not pbar is None:\n",
    "        pbar.n=len(arrayChunks)\n",
    "        pbar.refresh()\n",
    "    for iChunk,arrayChunk in enumerate(arrayChunks):\n",
    "        outPath='.'.join([pathBase,'chunk_%s'%(digitStr%iChunk),'npy'])\n",
    "        np.save(outPath,arrayChunk)\n",
    "        if not pbar is None:\n",
    "            pbar.update()\n",
    "            \n",
    "def loadArrayChunks(pathBase,nChunks,axis=0,\n",
    "                    pbar=None):\n",
    "    arrayChunks=[]\n",
    "    ndigits=int(np.ceil(np.log10(nChunks)))\n",
    "    digitStr='%'+'0%g'%ndigits+'g'\n",
    "    if not pbar is None:\n",
    "        pbar.n=len(arrayChunks)\n",
    "        pbar.refresh()\n",
    "    for iChunk in np.arange(nChunks):\n",
    "        dataPath='.'.join([pathBase,'chunk_%s'%(digitStr%iChunk),'npy'])\n",
    "        arrayChunks.append(np.load(dataPath))\n",
    "        if not pbar is None:\n",
    "            pbar.update()\n",
    "    return np.concatenate(arrayChunks,axis=axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can load the center of mass data set for each system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data sets "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8628db6abfac4a70b5922a32e7a298d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style=u'info', max=1), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " POPC POPS PIP2 \n",
      "\n",
      "done loading data\n",
      "--- --- ---\n",
      "POPC (1176, 2001, 3)\n",
      "POPS (1282, 1592, 3)\n",
      "PIP2 (1290, 1592, 3)\n"
     ]
    }
   ],
   "source": [
    "dataFileDir='dataFiles'\n",
    "comDataDir='/'.join([dataFileDir,'headgroupCoords'])\n",
    "leafletClusteringDir='/'.join([dataFileDir,'leafletClustering'])\n",
    "\n",
    "comFileTypeName='headgroup_COM_coords'\n",
    "\n",
    "systems=['POPC','POPS','PIP2']\n",
    "\n",
    "nChunks=4\n",
    "\n",
    "comDataDict={}\n",
    "print 'Loading data sets ',\n",
    "with tqdm.tqdm_notebook() as pbar:\n",
    "    for system in systems:\n",
    "        print system,\n",
    "        pbar.set_description_str(system)\n",
    "        comFileNameBase='.'.join([system,comFileTypeName])\n",
    "        comFilePathBase='/'.join([comDataDir,comFileNameBase])\n",
    "        comDataDict[system]=loadArrayChunks(comFilePathBase,nChunks=nChunks,axis=1,\n",
    "                                            pbar=pbar)\n",
    "        gc.collect()\n",
    "    print ''\n",
    "print 'done loading data'\n",
    "print '--- --- --- ---'\n",
    "\n",
    "for setKey in comDataDict:\n",
    "    print setKey,\n",
    "    print comDataDict[setKey].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the center of mass data for each system. Before diving straight into clustering,\n",
    "lets have a look at them visually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "137a8cb5be254fdb91c7591fc5b899ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aW50ZXJhY3RpdmUoY2hpbGRyZW49KERyb3Bkb3duKGRlc2NyaXB0aW9uPXUnU3lzdGVtOiAnLCBvcHRpb25zPSgnUE9QQycsICdQT1BTJywgJ1BJUDInKSwgdmFsdWU9J1BPUEMnKSwgSW50U2zigKY=\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plotGrids>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "systemWidget=widgets.Dropdown(\n",
    "                 options=comDataDict.keys(),\n",
    "                 description='System: ')\n",
    "frameWidget=widgets.IntSlider(description='Frame:',\n",
    "                              continuous_update=False)\n",
    "\n",
    "def updateFrameRange(*args):\n",
    "    frameRange=[0,comDataDict[systemWidget.value].shape[1]-1]\n",
    "    frameWidget.min=frameRange[0]\n",
    "    frameWidget.max=frameRange[1]\n",
    "    frameWidget.value=np.clip(frameWidget.value,\n",
    "                              frameRange[0],\n",
    "                              frameRange[1])\n",
    "frameWidget.observe(updateFrameRange)\n",
    "\n",
    "def plotGrids(systemName,frameNumber):\n",
    "    frame=np.clip(\n",
    "            frameNumber,\n",
    "            0,\n",
    "            comDataDict[systemName].shape[1]-1)\n",
    "    comData=comDataDict[systemName][\n",
    "        :,\n",
    "        frame,\n",
    "        :]\n",
    "    fig,axs=plt.subplots(1,3)\n",
    "    fig.set_figheight(4)\n",
    "    fig.set_figwidth(12)\n",
    "    \n",
    "    ax=axs.flat[0]\n",
    "    ax.scatter(comData[:,0],comData[:,1])\n",
    "    ax.set_title('%s: XY, frame %g'%(systemName,frame))\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    \n",
    "    ax=axs.flat[1]\n",
    "    ax.scatter(comData[:,0],comData[:,2])\n",
    "    ax.set_title('%s: XZ, frame %g'%(systemName,frame))\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Z')\n",
    "    \n",
    "    ax=axs.flat[2]\n",
    "    ax.scatter(comData[:,1],comData[:,2])\n",
    "    ax.set_title('%s: YZ, frame %g'%(systemName,frame))\n",
    "    ax.set_xlabel('Y')\n",
    "    ax.set_ylabel('Z')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "interact(plotGrids,\n",
    "         systemName=systemWidget,\n",
    "         frameNumber=frameWidget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the most part the leaflets appear to have a decent separation based on these phosphate group center of mass coordinates. We will now run DBSCAN over each data set to see how well it performs.\n",
    "\n",
    "There a few points to consider when using DBSCAN for this.\n",
    "    \n",
    "    1) DBSCAN will often assign points to an 'outlier' cluster (always labeled -1).\n",
    "        * These points will need to be assigned to the leaflets somehow.\n",
    "        * The simplest solution is to put them into the cluster which contains the nearest point\n",
    "    2) DBSCAN may find more clusters than we want (i.e. we want 2 it may find more)\n",
    "        * Extra clusters will need to be merged somehow.\n",
    "        * For now, lets just points in any additional clusters as outliers (see above)\n",
    "    3) DBSCAN may fail to put points in the right cluster. Given the curved shape of these membranes,\n",
    "       it is quite likely that DBSCAN could mistake the lower chunk of one leaflet as a part the other.\n",
    "       When this occurs, we will see a large number of points switch from one cluster to another.\n",
    "         * Anomaly detection can help here. We will address this shortly.\n",
    "         \n",
    "Below, we define a function that will take a set of coordinate data and attempt to cluster it into $N$ given number of clusters using DBSCAN. Any outliers will be forced into the cluster that contains the nearest point.\n",
    "The algorithm will attempt to iteratively modulate eps using a binary search scheme to try to generate the give number of clusters. If this fails and too many clusters are found, any clusters beyond the first $N$ found will be reassigned (all points within will be treated as outliers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLeafletInds(coordData,nClusters=2,maxIter=100,verbose=False,\n",
    "                   epsStart=16,tqdmOb=None,*args,**kwargs):\n",
    "    '''Takes\n",
    "        coordData: the coordinates to be clustered (should be a single frame)\n",
    "        nClusters: the target number of clusters\n",
    "        epsStart: starting guess for the needed eps value used by DBSCAN\n",
    "        maxIter: the number of allowed iterations before giving up\n",
    "        args,kwargs: optional arguments to be fed to DBSCAN'''\n",
    "    epsVal=epsStart\n",
    "    DBSCANob=skl.cluster.DBSCAN(eps=epsVal,*args,**kwargs)\n",
    "    clustVals=DBSCANob.fit_predict(coordData)\n",
    "    nVals=len(np.unique(clustVals[clustVals>-1]))\n",
    "    iIter=0\n",
    "    epsMin=0 #eps is an effective distance, so must be greater than 1\n",
    "    epsMax=np.sqrt(\n",
    "        np.sum(\n",
    "            (\n",
    "                np.max(coordData,axis=0)-\\\n",
    "                np.min(coordData,axis=0)\n",
    "            )**2))/2 #eps should never be greater than radius of coordinate bounds\n",
    "    #we well implement a basic binary search to find the needed eps\n",
    "    if verbose:\n",
    "        if tqdmOb is None:\n",
    "            pbar=tqdm.tqdm_notebook(np.arange(maxIter))\n",
    "        else:\n",
    "            pbar=tqdmOb\n",
    "            pbar.total=maxIter\n",
    "            pbar.n=0\n",
    "            pbar.clear()\n",
    "            #pbar.reset()\n",
    "            pbar.refresh()\n",
    "            pbar.set_description('Clustering Iteration:')\n",
    "    while (nVals!=nClusters) & (iIter<maxIter):\n",
    "        if verbose:\n",
    "            pbar.set_description_str('it: %g, nClust: %g, eps: %.4e'%(\n",
    "                iIter,nVals,epsVal))\n",
    "        if nVals<nClusters:\n",
    "            #too many clusters, eps is too large\n",
    "            epsMax=epsVal\n",
    "        if nVals>nClusters:\n",
    "            #too few clusters, eps is too small\n",
    "            epsMin=epsVal\n",
    "        epsVal=(epsMax+epsMin)/2\n",
    "        DBSCANob=skl.cluster.DBSCAN(eps=epsVal,*args,**kwargs)\n",
    "        clustVals=DBSCANob.fit_predict(coordData)\n",
    "        nVals=len(np.unique(clustVals[clustVals>-1]))\n",
    "        iIter=iIter+1\n",
    "        if verbose: \n",
    "            pbar.update()\n",
    "    if verbose:\n",
    "        pbar.update(maxIter-iIter)\n",
    "        if tqdmOb is None:\n",
    "            pbar.close()\n",
    "    if nVals != nClusters:\n",
    "        print \"WARNING! Failed to compute target number of clusters!\"\n",
    "        print \"         First nClusters identified clusters will be used\"\n",
    "        print np.unique(clustVals[clustVals>-1])\n",
    "    #if verbose:    \n",
    "    #    print 'Assigning outliers and excess cluster points'\n",
    "    outlierInds=np.argwhere((clustVals<0) | (clustVals>=nClusters)).flatten()\n",
    "    if len(outlierInds)>0:\n",
    "        goodInds=np.argwhere((clustVals>=0)&(clustVals<nClusters)).flatten()\n",
    "        nearestInds=skl.metrics.pairwise_distances_argmin(\n",
    "            coordData[outlierInds],coordData[goodInds])\n",
    "        nearestClusters=clustVals[nearestInds]\n",
    "        #print nearestInds\n",
    "        #print nearestClusters\n",
    "        clustVals[outlierInds]=nearestClusters\n",
    "    return clustVals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5b44b217e4947d68df595b8b36ea771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style=u'info', max=1), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd8521af33914e1c9d720c59b5047177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style=u'info', max=1), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9187042b21cb409ab14fb5dfb0569cc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style=u'info', max=1), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Failed to compute target number of clusters!\n",
      "         First nClusters identified clusters will be used\n",
      "[0]\n",
      "WARNING! Failed to compute target number of clusters!\n",
      "         First nClusters identified clusters will be used\n",
      "[0 1 2]\n",
      "WARNING! Failed to compute target number of clusters!\n",
      "         First nClusters identified clusters will be used\n",
      "[0 1 2]\n",
      "WARNING! Failed to compute target number of clusters!\n",
      "         First nClusters identified clusters will be used\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "leafletIDdict={}\n",
    "\n",
    "with tqdm.tqdm_notebook() as pbar:\n",
    "    with tqdm.tqdm_notebook() as pbarFrame:\n",
    "        with tqdm.tqdm_notebook() as pbarInner:\n",
    "            pbar.total=len(systems)\n",
    "            pbar.n=0\n",
    "            pbar.clear()\n",
    "            #pbar.reset()\n",
    "            pbar.refresh()\n",
    "            for system in systems:\n",
    "                comData=comDataDict[system]\n",
    "                pbarFrame.total=comData.shape[1]\n",
    "                pbarFrame.n=0\n",
    "                pbarFrame.clear()\n",
    "                #pbarFrame.reset()\n",
    "                pbarFrame.refresh()\n",
    "                pbar.set_description('System:')\n",
    "                pbar.set_description_str(system)\n",
    "                leafletIDs=np.zeros([comData.shape[1],comData.shape[0]])\n",
    "                for iFrame in np.arange(comData.shape[1]):\n",
    "                    pbarFrame.set_description('Frame')\n",
    "                    pbarFrame.set_description_str('%g'%iFrame)\n",
    "                    leafletIDs[iFrame,:]=getLeafletInds(\n",
    "                        comData[:,iFrame,:],\n",
    "                        verbose=True,\n",
    "                        tqdmOb=pbarInner)\n",
    "                    pbarFrame.update()\n",
    "                leafletIDdict[system]=copy.deepcopy(leafletIDs)\n",
    "                pbar.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have clustering data for all three systems to help us determine which leaflet each lipid belongs to...\n",
    "\n",
    "Unfortunately, DBSCAN seems to fail occasionally. Lets have a look at how things turned out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 1., 1.],\n",
       "       [0., 0., 0., ..., 1., 1., 1.],\n",
       "       [0., 0., 0., ..., 1., 1., 1.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 1., 1.],\n",
       "       [0., 0., 0., ..., 1., 1., 1.],\n",
       "       [0., 0., 0., ..., 1., 1., 1.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leafletIDdict['PIP2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19f8701717d34491a96a1cfd54e5fd20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aW50ZXJhY3RpdmUoY2hpbGRyZW49KERyb3Bkb3duKGRlc2NyaXB0aW9uPXUnU3lzdGVtOiAnLCBvcHRpb25zPSgnUE9QQycsICdQT1BTJywgJ1BJUDInKSwgdmFsdWU9J1BPUEMnKSwgSW50U2zigKY=\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plotClusters>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib.patches import Rectangle\n",
    "frame=0\n",
    "#fig=plt.figure(figsize=(9,6))\n",
    "#plt.imshow(np.abs(leafletIDs[1:]-leafletIDs[:-1]).T)\n",
    "#plt.show()\n",
    "\n",
    "systemWidget=widgets.Dropdown(\n",
    "                 options=comDataDict.keys(),\n",
    "                 description='System: ')\n",
    "frameWidget=widgets.IntSlider(description='Frame:',\n",
    "                              step=1,\n",
    "                              continuous_update=False)\n",
    "\n",
    "def updateFrameRange(*args):\n",
    "    frameRange=[0,comDataDict[systemWidget.value].shape[1]-1]\n",
    "    frameWidget.min=frameRange[0]\n",
    "    frameWidget.max=frameRange[1]\n",
    "    frameWidget.value=np.clip(frameWidget.value,\n",
    "                              frameRange[0],\n",
    "                              frameRange[1])\n",
    "frameWidget.observe(updateFrameRange)\n",
    "\n",
    "def plotClusters(systemName,frameNumber):\n",
    "    comData=comDataDict[systemName]\n",
    "    leafletIDs=leafletIDdict[systemName]\n",
    "    frame=np.clip(frameNumber,0,comData.shape[1]-1)\n",
    "    fig=plt.figure(figsize=(12,6))\n",
    "    recArgs0={'facecolor':'#aa22aa','alpha':.20}\n",
    "    recArgs1={'facecolor':'#bb44bb','alpha':.25}\n",
    "    recArgs2={'facecolor':'#cc88cc','alpha':.30}\n",
    "    #plt.imshow(np.abs(leafletIDs[1:]-leafletIDs[:-1]).T)\n",
    "    plt.imshow(leafletIDs.T)\n",
    "    plt.gca().add_patch(\n",
    "            plt.Rectangle(\n",
    "                (frame-30,0),61,comData.shape[0],0.0,\n",
    "                **recArgs0))\n",
    "    plt.gca().add_patch(\n",
    "            plt.Rectangle(\n",
    "                (frame-13,0),25,comData.shape[0],0.0,\n",
    "                **recArgs1))\n",
    "    plt.gca().add_patch(\n",
    "            plt.Rectangle(\n",
    "                (frame-3,0),5,comData.shape[0],0.0,\n",
    "                **recArgs2))\n",
    "    plt.show()\n",
    "    coordData=comData[:,frame,:]\n",
    "    testClust=leafletIDs[frame]\n",
    "\n",
    "    colorSet=['#aa0000','#00aa00','#0000aa',\n",
    "              '#664444','#446644','#444466',\n",
    "              '#223344','#334422','#442233',\n",
    "              '#443322','#332244','#224433']\n",
    "    fig,axs=plt.subplots(2,2)\n",
    "    fig.set_figheight(9)\n",
    "    fig.set_figwidth(12)\n",
    "    for iClust,cid in enumerate(np.unique(testClust)):\n",
    "        cInds=(testClust==cid)\n",
    "        #print iClust\n",
    "        xDat=comData[cInds,frame,0]\n",
    "        yDat=comData[cInds,frame,2]\n",
    "        cDat=[iClust]*len(xDat)\n",
    "        ax=axs.flat[0]\n",
    "        ax.scatter(comData[cInds,frame,0],\n",
    "                    comData[cInds,frame,2],\n",
    "                    c=colorSet[iClust],\n",
    "                    label='cluster %g'%cid,\n",
    "                    s=1)\n",
    "        ax=axs.flat[1]\n",
    "        ax.scatter(comData[cInds,frame,1],\n",
    "                    comData[cInds,frame,2],\n",
    "                    c=colorSet[iClust],\n",
    "                    label='cluster %g'%cid,\n",
    "                    s=1)\n",
    "        ax=axs.flat[2]\n",
    "        ax.scatter(comData[cInds,frame,0],\n",
    "                    comData[cInds,frame,1],\n",
    "                    c=colorSet[iClust],\n",
    "                    label='cluster %g'%cid,\n",
    "                    s=1)\n",
    "    axs.flat[0].legend()\n",
    "    axs.flat[0].set_xlabel('x')\n",
    "    axs.flat[0].set_ylabel('z')\n",
    "    axs.flat[1].legend()\n",
    "    axs.flat[1].set_xlabel('y')\n",
    "    axs.flat[1].set_ylabel('z')\n",
    "    axs.flat[2].legend()\n",
    "    axs.flat[2].set_xlabel('x')\n",
    "    axs.flat[2].set_ylabel('y')\n",
    "    print 'Reciprocal DB score: %.3f'%(\n",
    "        skl.metrics.davies_bouldin_score(coordData,testClust))\n",
    "    plt.show()\n",
    "    \n",
    "interact(plotClusters,\n",
    "         systemName=systemWidget,\n",
    "         frameNumber=frameWidget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
